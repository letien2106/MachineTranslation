{"cells":[{"cell_type":"markdown","metadata":{"id":"view-in-github"},"source":["<a href=\"https://colab.research.google.com/github/TheDuyIT/MachineTranslation/blob/master/src/transformer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2493,"status":"ok","timestamp":1652849916540,"user":{"displayName":"Tiến Lê Văn","userId":"05205815886898954704"},"user_tz":-420},"id":"kB9BXDZLyrMG","outputId":"603cb3b9-eb1f-4e4f-a469-eac400428370"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JjJJyJTZYebt"},"outputs":[],"source":["import tensorflow_datasets as tfds\n","import tensorflow as tf\n","import unicodedata\n","import time\n","import re\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import jieba\n","import pandas as pd\n","from sklearn.utils import shuffle"]},{"cell_type":"markdown","metadata":{"id":"fd1NWMxjfsDd"},"source":["## Setup input pipeline"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11513,"status":"ok","timestamp":1652849931957,"user":{"displayName":"Tiến Lê Văn","userId":"05205815886898954704"},"user_tz":-420},"id":"6vjL2xyb4PHc","outputId":"4b8e5db8-8d7d-4417-a5e8-590e12021e31"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(87267, 2)"]},"metadata":{},"execution_count":11}],"source":["# dataset = pd.read_excel(\"/content/drive/MyDrive/Colab Notebooks/Project/dataMe/cn_vn_8k.xlsx\").drop(columns=[\"Unnamed: 0\"])\n","# # dataset = dataset[:20000]\n","# content_vn = dataset[\"Viet\"]\n","# content_cn = dataset[\"Trung\"]\n","# dataset.shape"]},{"cell_type":"code","source":["# dataset.drop_duplicates()\n","# dataset.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-turaZSfdnzw","executionInfo":{"status":"ok","timestamp":1652786930179,"user_tz":-420,"elapsed":11,"user":{"displayName":"Tiến Lê Văn","userId":"05205815886898954704"}},"outputId":"b873c718-b8cf-4d7d-eb18-ca5a9c23ace1"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(87267, 2)"]},"metadata":{},"execution_count":75}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1652786905924,"user":{"displayName":"Tiến Lê Văn","userId":"05205815886898954704"},"user_tz":-420},"id":"hbixJHrp4Ua9","outputId":"b339f07f-ed60-43bd-9814-c5b1036ec449"},"outputs":[{"output_type":"stream","name":"stdout","text":["931\n","1\n","231\n","1\n"]}],"source":["# print(len(max(vi_input, key=len)))\n","# print(len(min(vi_input, key=len)))\n","\n","# print(len(max(cn_input, key=len)))\n","# print(len(min(cn_input, key=len)))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11411,"status":"ok","timestamp":1652851407031,"user":{"displayName":"Tiến Lê Văn","userId":"05205815886898954704"},"user_tz":-420},"id":"KyhkTzEzFg9C","outputId":"53c133c1-60f4-4ee2-e9fc-d82a10446d17"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(3000, 2)"]},"metadata":{},"execution_count":102}],"source":["dataset = pd.read_excel(\"/content/drive/MyDrive/Colab Notebooks/cn_vn.xlsx\").drop(columns=[\"Unnamed: 0\"])\n","dataset = dataset[:3000]\n","dataset = shuffle(dataset, random_state=42)\n","content_vn = dataset[\"Viet\"]\n","content_cn = dataset[\"Trung\"]\n","dataset.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1652851407032,"user":{"displayName":"Tiến Lê Văn","userId":"05205815886898954704"},"user_tz":-420},"id":"K-daNI6J25nz","outputId":"156dfeab-b0d1-4ab0-8a1c-9f7262ec7a7e"},"outputs":[{"output_type":"stream","name":"stdout","text":["99\n","6\n","96\n","1\n"]}],"source":["print(len(max(content_vn, key=len)))\n","print(len(min(content_vn, key=len)))\n","\n","print(len(max(content_cn, key=len)))\n","print(len(min(content_cn, key=len)))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZpF0MBnRaq2o"},"outputs":[],"source":["def preproces_cn(s):\n","  return re.sub('\\s+', ' ', ' '.join(s))\n","  seg_list = jieba.cut(s)\n","  return \" \".join(seg_list)\n","\n","for i in range(len(content_vn)):\n","  content_vn[i] = content_vn[i].lower()\n","for i in range(len(content_cn)):\n","  content_cn[i] = preproces_cn(content_cn[i])\n","# content_cn"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1652851407524,"user":{"displayName":"Tiến Lê Văn","userId":"05205815886898954704"},"user_tz":-420},"id":"f0gpS90X3cbi","outputId":"4680eaaf-a6aa-4dae-eb25-77e9f8be948e"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'“ 带 我 们 进 风 云 阁 。 ”'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":105}],"source":["content_cn[3]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1652851407524,"user":{"displayName":"Tiến Lê Văn","userId":"05205815886898954704"},"user_tz":-420},"id":"VP0PoNkyDIHp","outputId":"93637428-9aef-4690-f98b-273c06120c74"},"outputs":[{"output_type":"stream","name":"stdout","text":["3000\n","3000\n"]}],"source":["print(len(content_cn))\n","print(len(content_vn))"]},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","X_train, X_test, y_train, y_test = train_test_split(content_cn, content_vn, test_size=0.2, random_state=1)\n","X_val, y_val = [X_train[0]], [y_train[0]]\n","\n","def create_dataset(x, y):\n","  a = tf.data.Dataset.from_tensor_slices(x)  # ==> [ 1, 2, 3 ]\n","  b = tf.data.Dataset.from_tensor_slices(y)\n","  ds = tf.data.Dataset.zip((a, b))\n","  ds = ds.shuffle(buffer_size = 1000)\n","  return ds"],"metadata":{"id":"rIGDPQBiiuWo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["full_dataset = create_dataset(content_cn, content_vn)\n","train_examples = create_dataset(X_train, y_train)\n","test_dataset = create_dataset(X_test, y_test)\n","val_dataset = create_dataset(X_val, y_val)\n","# train_examples = full_dataset.take(train_size)\n","# test_dataset = full_dataset.skip(train_size)\n","# val_dataset = test_dataset.skip(val_size)\n","# test_dataset = test_dataset.take(test_size)\n","print(f'{len(full_dataset)} total pairs')\n","print(f'{len(train_examples)} training pairs')\n","print(f'{len(val_dataset)} validation pairs')\n","print(f'{len(test_dataset)} test pairs')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"J2oIvKvHh4IM","executionInfo":{"status":"ok","timestamp":1652851563063,"user_tz":-420,"elapsed":291,"user":{"displayName":"Tiến Lê Văn","userId":"05205815886898954704"}},"outputId":"ef930582-79bc-41a6-91b1-e844d2c57ae5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["3000 total pairs\n","2400 training pairs\n","1 validation pairs\n","600 test pairs\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KVBg5Q8tBk5z"},"outputs":[],"source":["# tokenizer_vn = tfds.deprecated.text.SubwordTextEncoder.load_from_file('tokenizer_cn')\n","# tokenizer_cn = tfds.deprecated.text.SubwordTextEncoder.load_from_file('tokenizer_vn')\n","tokenizer_cn = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(\n","    (en.numpy() for en, _ in full_dataset), target_vocab_size=2**13)\n","\n","tokenizer_vn = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(\n","    (vn.numpy() for _, vn in full_dataset), target_vocab_size=2**13)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":320,"status":"ok","timestamp":1652851087719,"user":{"displayName":"Tiến Lê Văn","userId":"05205815886898954704"},"user_tz":-420},"id":"pJI9HChXrVch","outputId":"d314c8e2-7cb6-4843-b09c-968694a95626"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["8183"]},"metadata":{},"execution_count":56}],"source":["tokenizer_cn.vocab_size"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uH_zOTI_3jg-"},"outputs":[],"source":["# for i in range(tokenizer_cn.vocab_size):\n","#   print(f'{i} ----> {tokenizer_cn.zzdecode([i])}')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-9ddMZP5z3tp"},"outputs":[],"source":["# tokenizer_cn.save_to_file('/content/drive/MyDrive/Colab Notebooks/tokenizer_cn')\n","# tokenizer_vn.save_to_file('/content/drive/MyDrive/Colab Notebooks/tokenizer_vn')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bcRp7VcQ5m6g"},"outputs":[],"source":["BUFFER_SIZE = 2000\n","BATCH_SIZE = 64"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UZwnPr4R055s"},"outputs":[],"source":["def encode(lang1, lang2):\n","  lang1 = [tokenizer_cn.vocab_size] + tokenizer_cn.encode(\n","      lang1.numpy()) + [tokenizer_cn.vocab_size+1]\n","\n","  lang2 = [tokenizer_vn.vocab_size] + tokenizer_vn.encode(\n","      lang2.numpy()) + [tokenizer_vn.vocab_size+1]\n","  \n","  return lang1, lang2"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Mah1cS-P70Iz"},"outputs":[],"source":["def tf_encode(en, vn):\n","  result_en, result_vn = tf.py_function(encode, [en, vn], [tf.int64, tf.int64])\n","  result_en.set_shape([None])\n","  result_vn.set_shape([None])\n","\n","  return result_en, result_vn"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2QEgbjntk6Yf"},"outputs":[],"source":["MAX_LENGTH = 250\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"c081xPGv1CPI"},"outputs":[],"source":["def filter_max_length(x, y, max_length=MAX_LENGTH):\n","  return tf.logical_and(tf.size(x) <= max_length,\n","                        tf.size(y) <= max_length)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JKIPFkLr-Qsz"},"outputs":[],"source":["train_dataset = train_examples.map(tf_encode)\n","train_dataset = train_dataset.filter(filter_max_length)\n","# cache the dataset to memory to get a speedup while reading from it.\n","train_dataset = train_dataset.cache()\n","train_dataset = train_dataset.shuffle(BUFFER_SIZE).padded_batch(BATCH_SIZE)\n","train_dataset = train_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n","\n","\n","val_dataset = val_dataset.map(tf_encode)\n","val_dataset = val_dataset.filter(filter_max_length).padded_batch(BATCH_SIZE)\n","\n","test_dataset = test_dataset.map(tf_encode)\n","test_dataset = test_dataset.filter(filter_max_length).padded_batch(BATCH_SIZE)"]},{"cell_type":"markdown","metadata":{"id":"nBQuibYA4n0n"},"source":["## Positional encoding\n","\n","Since this model doesn't contain any recurrence or convolution, positional encoding is added to give the model some information about the relative position of the words in the sentence. \n","\n","The positional encoding vector is added to the embedding vector. Embeddings represent a token in a d-dimensional space where tokens with similar meaning will be closer to each other. But the embeddings do not encode the relative position of words in a sentence. So after adding the positional encoding, words will be closer to each other based on the *similarity of their meaning and their position in the sentence*, in the d-dimensional space.\n","\n","See the notebook on [positional encoding](https://github.com/tensorflow/examples/blob/master/community/en/position_encoding.ipynb) to learn more about it. The formula for calculating the positional encoding is as follows:\n","\n","$$\\Large{PE_{(pos, 2i)} = sin(pos / 10000^{2i / d_{model}})} $$\n","$$\\Large{PE_{(pos, 2i+1)} = cos(pos / 10000^{2i / d_{model}})} $$"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WhIOZjMNKujn"},"outputs":[],"source":["def get_angles(pos, i, d_model):\n","  angle_rates = 1 / np.power(10000, (2 * (i//2)) / np.float32(d_model))\n","  return pos * angle_rates"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1Rz82wEs5biZ"},"outputs":[],"source":["def positional_encoding(position, d_model):\n","  angle_rads = get_angles(np.arange(position)[:, np.newaxis],\n","                          np.arange(d_model)[np.newaxis, :],\n","                          d_model)\n","  \n","  # apply sin to even indices in the array; 2i\n","  angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n","  \n","  # apply cos to odd indices in the array; 2i+1\n","  angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n","    \n","  pos_encoding = angle_rads[np.newaxis, ...]\n","    \n","  return tf.cast(pos_encoding, dtype=tf.float32)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":301},"executionInfo":{"elapsed":546,"status":"ok","timestamp":1652851574194,"user":{"displayName":"Tiến Lê Văn","userId":"05205815886898954704"},"user_tz":-420},"id":"1kLCla68EloE","outputId":"d099786a-8878-4a79-c235-89502effd8dc"},"outputs":[{"output_type":"stream","name":"stdout","text":["(1, 50, 512)\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 2 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}],"source":["pos_encoding = positional_encoding(50, 512)\n","print (pos_encoding.shape)\n","\n","plt.pcolormesh(pos_encoding[0], cmap='RdBu')\n","plt.xlabel('Depth')\n","plt.xlim((0, 512))\n","plt.ylabel('Position')\n","plt.colorbar()\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"a_b4ou4TYqUN"},"source":["## Masking"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"U2i8-e1s8ti9"},"outputs":[],"source":["def create_padding_mask(seq):\n","  seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n","  \n","  # add extra dimensions to add the padding\n","  # to the attention logits.\n","  return seq[:, tf.newaxis, tf.newaxis, :]  # (batch_size, 1, 1, seq_len)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dVxS8OPI9uI0"},"outputs":[],"source":["def create_look_ahead_mask(size):\n","  mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n","  return mask  # (seq_len, seq_len)"]},{"cell_type":"markdown","metadata":{"id":"xluDl5cXYy4y"},"source":["## Scaled dot product attention"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LazzUq3bJ5SH"},"outputs":[],"source":["def scaled_dot_product_attention(q, k, v, mask):\n","  \"\"\"Calculate the attention weights.\n","  q, k, v must have matching leading dimensions.\n","  k, v must have matching penultimate dimension, i.e.: seq_len_k = seq_len_v.\n","  The mask has different shapes depending on its type(padding or look ahead) \n","  but it must be broadcastable for addition.\n","  \n","  Args:\n","    q: query shape == (..., seq_len_q, depth)\n","    k: key shape == (..., seq_len_k, depth)\n","    v: value shape == (..., seq_len_v, depth_v)\n","    mask: Float tensor with shape broadcastable \n","          to (..., seq_len_q, seq_len_k). Defaults to None.\n","    \n","  Returns:\n","    output, attention_weights\n","  \"\"\"\n","\n","  matmul_qk = tf.matmul(q, k, transpose_b=True)  # (..., seq_len_q, seq_len_k)\n","  \n","  # scale matmul_qk\n","  dk = tf.cast(tf.shape(k)[-1], tf.float32)\n","  scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n","\n","  # add the mask to the scaled tensor.\n","  if mask is not None:\n","    scaled_attention_logits += (mask * -1e9)  \n","\n","  # softmax is normalized on the last axis (seq_len_k) so that the scores\n","  # add up to 1.\n","  attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)  # (..., seq_len_q, seq_len_k)\n","\n","  output = tf.matmul(attention_weights, v)  # (..., seq_len_q, depth_v)\n","\n","  return output, attention_weights"]},{"cell_type":"markdown","metadata":{"id":"kmzGPEy64qmA"},"source":["## Multi-head attention"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BSV3PPKsYecw"},"outputs":[],"source":["class MultiHeadAttention(tf.keras.layers.Layer):\n","  def __init__(self, d_model, num_heads):\n","    super(MultiHeadAttention, self).__init__()\n","    self.num_heads = num_heads\n","    self.d_model = d_model\n","    \n","    assert d_model % self.num_heads == 0\n","    \n","    self.depth = d_model // self.num_heads\n","    \n","    self.wq = tf.keras.layers.Dense(d_model)\n","    self.wk = tf.keras.layers.Dense(d_model)\n","    self.wv = tf.keras.layers.Dense(d_model)\n","    \n","    self.dense = tf.keras.layers.Dense(d_model)\n","        \n","  def split_heads(self, x, batch_size):\n","    \"\"\"Split the last dimension into (num_heads, depth).\n","    Transpose the result such that the shape is (batch_size, num_heads, seq_len, depth)\n","    \"\"\"\n","    x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n","    return tf.transpose(x, perm=[0, 2, 1, 3])\n","    \n","  def call(self, v, k, q, mask):\n","    batch_size = tf.shape(q)[0]\n","    \n","    q = self.wq(q)  # (batch_size, seq_len, d_model)\n","    k = self.wk(k)  # (batch_size, seq_len, d_model)\n","    v = self.wv(v)  # (batch_size, seq_len, d_model)\n","    \n","    q = self.split_heads(q, batch_size)  # (batch_size, num_heads, seq_len_q, depth)\n","    k = self.split_heads(k, batch_size)  # (batch_size, num_heads, seq_len_k, depth)\n","    v = self.split_heads(v, batch_size)  # (batch_size, num_heads, seq_len_v, depth)\n","    \n","    # scaled_attention.shape == (batch_size, num_heads, seq_len_q, depth)\n","    # attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)\n","    scaled_attention, attention_weights = scaled_dot_product_attention(\n","        q, k, v, mask)\n","    \n","    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])  # (batch_size, seq_len_q, num_heads, depth)\n","\n","    concat_attention = tf.reshape(scaled_attention, \n","                                  (batch_size, -1, self.d_model))  # (batch_size, seq_len_q, d_model)\n","\n","    output = self.dense(concat_attention)  # (batch_size, seq_len_q, d_model)\n","        \n","    return output, attention_weights"]},{"cell_type":"markdown","metadata":{"id":"RdDqGayx67vv"},"source":["## Point wise feed forward network"]},{"cell_type":"markdown","metadata":{"id":"gBqzJXGfHK3X"},"source":["Point wise feed forward network consists of two fully-connected layers with a ReLU activation in between."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ET7xLt0yCT6Z"},"outputs":[],"source":["def point_wise_feed_forward_network(d_model, dff):\n","  return tf.keras.Sequential([\n","      tf.keras.layers.Dense(dff, activation='relu'),  # (batch_size, seq_len, dff)\n","      tf.keras.layers.Dense(d_model)  # (batch_size, seq_len, d_model)\n","  ])"]},{"cell_type":"markdown","metadata":{"id":"7e7hKcxn6-zd"},"source":["## Encoder and decoder"]},{"cell_type":"markdown","metadata":{"id":"QFv-FNYUmvpn"},"source":["### Encoder layer\n","\n","Each encoder layer consists of sublayers:\n","\n","1.   Multi-head attention (with padding mask) \n","2.    Point wise feed forward networks. \n","\n","Each of these sublayers has a residual connection around it followed by a layer normalization. Residual connections help in avoiding the vanishing gradient problem in deep networks.\n","\n","The output of each sublayer is `LayerNorm(x + Sublayer(x))`. The normalization is done on the `d_model` (last) axis. There are N encoder layers in the transformer."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ncyS-Ms3i2x_"},"outputs":[],"source":["class EncoderLayer(tf.keras.layers.Layer):\n","  def __init__(self, d_model, num_heads, dff, rate=0.1):\n","    super(EncoderLayer, self).__init__()\n","\n","    self.mha = MultiHeadAttention(d_model, num_heads)\n","    self.ffn = point_wise_feed_forward_network(d_model, dff)\n","\n","    self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n","    self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n","    \n","    self.dropout1 = tf.keras.layers.Dropout(rate)\n","    self.dropout2 = tf.keras.layers.Dropout(rate)\n","    \n","  def call(self, x, training, mask):\n","\n","    attn_output, _ = self.mha(x, x, x, mask)  # (batch_size, input_seq_len, d_model)\n","    attn_output = self.dropout1(attn_output, training=training)\n","    out1 = self.layernorm1(x + attn_output)  # (batch_size, input_seq_len, d_model)\n","    \n","    ffn_output = self.ffn(out1)  # (batch_size, input_seq_len, d_model)\n","    ffn_output = self.dropout2(ffn_output, training=training)\n","    out2 = self.layernorm2(out1 + ffn_output)  # (batch_size, input_seq_len, d_model)\n","    \n","    return out2"]},{"cell_type":"markdown","metadata":{"id":"6LO_48Owmx_o"},"source":["### Decoder layer\n","\n","Each decoder layer consists of sublayers:\n","\n","1.   Masked multi-head attention (with look ahead mask and padding mask)\n","2.   Multi-head attention (with padding mask). V (value) and K (key) receive the *encoder output* as inputs. Q (query) receives the *output from the masked multi-head attention sublayer.*\n","3.   Point wise feed forward networks\n","\n","Each of these sublayers has a residual connection around it followed by a layer normalization. The output of each sublayer is `LayerNorm(x + Sublayer(x))`. The normalization is done on the `d_model` (last) axis.\n","\n","There are N decoder layers in the transformer.\n","\n","As Q receives the output from decoder's first attention block, and K receives the encoder output, the attention weights represent the importance given to the decoder's input based on the encoder's output. In other words, the decoder predicts the next word by looking at the encoder output and self-attending to its own output. See the demonstration above in the scaled dot product attention section."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9SoX0-vd1hue"},"outputs":[],"source":["class DecoderLayer(tf.keras.layers.Layer):\n","  def __init__(self, d_model, num_heads, dff, rate=0.1):\n","    super(DecoderLayer, self).__init__()\n","\n","    self.mha1 = MultiHeadAttention(d_model, num_heads)\n","    self.mha2 = MultiHeadAttention(d_model, num_heads)\n","\n","    self.ffn = point_wise_feed_forward_network(d_model, dff)\n"," \n","    self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n","    self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n","    self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n","    \n","    self.dropout1 = tf.keras.layers.Dropout(rate)\n","    self.dropout2 = tf.keras.layers.Dropout(rate)\n","    self.dropout3 = tf.keras.layers.Dropout(rate)\n","    \n","    \n","  def call(self, x, enc_output, training, \n","           look_ahead_mask, padding_mask):\n","    # enc_output.shape == (batch_size, input_seq_len, d_model)\n","\n","    attn1, attn_weights_block1 = self.mha1(x, x, x, look_ahead_mask)  # (batch_size, target_seq_len, d_model)\n","    attn1 = self.dropout1(attn1, training=training)\n","    out1 = self.layernorm1(attn1 + x)\n","    \n","    attn2, attn_weights_block2 = self.mha2(\n","        enc_output, enc_output, out1, padding_mask)  # (batch_size, target_seq_len, d_model)\n","    attn2 = self.dropout2(attn2, training=training)\n","    out2 = self.layernorm2(attn2 + out1)  # (batch_size, target_seq_len, d_model)\n","    \n","    ffn_output = self.ffn(out2)  # (batch_size, target_seq_len, d_model)\n","    ffn_output = self.dropout3(ffn_output, training=training)\n","    out3 = self.layernorm3(ffn_output + out2)  # (batch_size, target_seq_len, d_model)\n","    \n","    return out3, attn_weights_block1, attn_weights_block2"]},{"cell_type":"markdown","metadata":{"id":"SE1H51Ajm0q1"},"source":["### Encoder\n","\n","The `Encoder` consists of:\n","1.   Input Embedding\n","2.   Positional Encoding\n","3.   N encoder layers\n","\n","The input is put through an embedding which is summed with the positional encoding. The output of this summation is the input to the encoder layers. The output of the encoder is the input to the decoder."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jpEox7gJ8FCI"},"outputs":[],"source":["class Encoder(tf.keras.layers.Layer):\n","  def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size,\n","               maximum_position_encoding, rate=0.1):\n","    super(Encoder, self).__init__()\n","    self.d_model = d_model\n","    self.num_layers = num_layers\n","    \n","    self.embedding = tf.keras.layers.Embedding(input_vocab_size, d_model)\n","    self.pos_encoding = positional_encoding(maximum_position_encoding, \n","                                            self.d_model)\n","    \n","    \n","    self.enc_layers = [EncoderLayer(d_model, num_heads, dff, rate) \n","                       for _ in range(num_layers)]\n","  \n","    self.dropout = tf.keras.layers.Dropout(rate)\n","        \n","  def call(self, x, training, mask):\n","\n","    seq_len = tf.shape(x)[1]\n","    \n","    # adding embedding and position encoding.\n","    x = self.embedding(x)  # (batch_size, input_seq_len, d_model)\n","    x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n","    x += self.pos_encoding[:, :seq_len, :]\n","\n","    x = self.dropout(x, training=training)\n","    \n","    for i in range(self.num_layers):\n","      x = self.enc_layers[i](x, training, mask)\n","    \n","    return x  # (batch_size, input_seq_len, d_model)"]},{"cell_type":"markdown","metadata":{"id":"p-uO6ls8m2O5"},"source":["### Decoder"]},{"cell_type":"markdown","metadata":{"id":"ZtT7PKzrXkNr"},"source":[" The `Decoder` consists of:\n","1.   Output Embedding\n","2.   Positional Encoding\n","3.   N decoder layers\n","\n","The target is put through an embedding which is summed with the positional encoding. The output of this summation is the input to the decoder layers. The output of the decoder is the input to the final linear layer."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d5_d5-PLQXwY"},"outputs":[],"source":["class Decoder(tf.keras.layers.Layer):\n","  def __init__(self, num_layers, d_model, num_heads, dff, target_vocab_size,\n","               maximum_position_encoding, rate=0.1):\n","    super(Decoder, self).__init__()\n","\n","    self.d_model = d_model\n","    self.num_layers = num_layers\n","    \n","    self.embedding = tf.keras.layers.Embedding(target_vocab_size, d_model)\n","    self.pos_encoding = positional_encoding(maximum_position_encoding, d_model)\n","    \n","    self.dec_layers = [DecoderLayer(d_model, num_heads, dff, rate) \n","                       for _ in range(num_layers)]\n","    self.dropout = tf.keras.layers.Dropout(rate)\n","    \n","  def call(self, x, enc_output, training, \n","           look_ahead_mask, padding_mask):\n","\n","    seq_len = tf.shape(x)[1]\n","    attention_weights = {}\n","    \n","    x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n","    x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n","    x += self.pos_encoding[:, :seq_len, :]\n","    \n","    x = self.dropout(x, training=training)\n","\n","    for i in range(self.num_layers):\n","      x, block1, block2 = self.dec_layers[i](x, enc_output, training,\n","                                             look_ahead_mask, padding_mask)\n","      \n","      attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n","      attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n","    \n","    # x.shape == (batch_size, target_seq_len, d_model)\n","    return x, attention_weights"]},{"cell_type":"markdown","metadata":{"id":"y54xnJnuYgJ7"},"source":["## Create the Transformer"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PED3bIpOYkBu"},"outputs":[],"source":["class Transformer(tf.keras.Model):\n","  def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, \n","               target_vocab_size, pe_input, pe_target, rate=0.1):\n","    super(Transformer, self).__init__()\n","    \n","    self.encoder = Encoder(num_layers, d_model, num_heads, dff, \n","                           input_vocab_size, pe_input, rate)\n","\n","    self.decoder = Decoder(num_layers, d_model, num_heads, dff, \n","                           target_vocab_size, pe_target, rate)\n","\n","    self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n","    \n","  def call(self, inp, tar, training, enc_padding_mask, \n","           look_ahead_mask, dec_padding_mask):\n","    \n","    enc_output = self.encoder(inp, training, enc_padding_mask)  # (batch_size, inp_seq_len, d_model)\n","    # dec_output.shape == (batch_size, tar_seq_len, d_model)\n","    dec_output, attention_weights = self.decoder(\n","        tar, enc_output, training, look_ahead_mask, dec_padding_mask)\n","    \n","    final_output = self.final_layer(dec_output)  # (batch_size, tar_seq_len, target_vocab_size)\n","    \n","    return final_output, attention_weights"]},{"cell_type":"markdown","metadata":{"id":"wsINyf1VEQLC"},"source":["## Set hyperparameters"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lnJn5SLA2ahP"},"outputs":[],"source":["num_layers = 6\n","d_model = 256 # model dim\n","dff = 512 # feed forward dim\n","num_heads = 8 # number of multi head attention d_model%num_heads == 0\n","\n","input_vocab_size = tokenizer_cn.vocab_size + 2\n","target_vocab_size = tokenizer_vn.vocab_size + 2\n","dropout_rate = 0.1"]},{"cell_type":"markdown","metadata":{"id":"xYEGhEOtzn5W"},"source":["## Optimizer"]},{"cell_type":"markdown","metadata":{"id":"GOmWW--yP3zx"},"source":["Use the Adam optimizer with a custom learning rate scheduler according to the formula in the [paper](https://arxiv.org/abs/1706.03762).\n","\n","$$\\Large{lrate = d_{model}^{-0.5} * min(step{\\_}num^{-0.5}, step{\\_}num * warmup{\\_}steps^{-1.5})}$$\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iYQdOO1axwEI"},"outputs":[],"source":["class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n","  def __init__(self, d_model, warmup_steps=4000):\n","    super(CustomSchedule, self).__init__()\n","    \n","    self.d_model = d_model\n","    self.d_model = tf.cast(self.d_model, tf.float32)\n","\n","    self.warmup_steps = warmup_steps\n","    \n","  def __call__(self, step):\n","    arg1 = tf.math.rsqrt(step)\n","    arg2 = step * (self.warmup_steps ** -1.5)\n","    \n","    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7r4scdulztRx"},"outputs":[],"source":["learning_rate = CustomSchedule(d_model)\n","\n","optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, \n","                                     epsilon=1e-9)"]},{"cell_type":"markdown","metadata":{"id":"YgkDE7hzo8r5"},"source":["## Loss and metrics"]},{"cell_type":"markdown","metadata":{"id":"oxGJtoDuYIHL"},"source":["Since the target sequences are padded, it is important to apply a padding mask when calculating the loss."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"67oqVHiT0Eiu"},"outputs":[],"source":["\n","def loss_function(real, pred):\n","  mask = tf.math.logical_not(tf.math.equal(real, 0))\n","  loss_ = loss_object(real, pred)\n","\n","  mask = tf.cast(mask, dtype=loss_.dtype)\n","  loss_ *= mask\n","  return tf.reduce_sum(loss_)/tf.reduce_sum(mask)\n","def accuracy_function(real, pred):\n","  # print('000000000000000000000000000')\n","  # print(real)\n","  # print('111111111111111111111111111')\n","  # print(pred)\n","  # print('222222222222222222222222222')\n","  # print(tf.argmax(pred, axis=2))\n","  # print('333333333333333333333333333')\n","\n","  accuracies = tf.equal(real, tf.argmax(pred, axis=2))\n","  # print(accuracies)\n","  # print('333333333333333333333333333')\n","  mask = tf.math.logical_not(tf.math.equal(real, 0))\n","  accuracies = tf.math.logical_and(mask, accuracies)\n","\n","  accuracies = tf.cast(accuracies, dtype=tf.float32)\n","  mask = tf.cast(mask, dtype=tf.float32)\n","  return tf.reduce_sum(accuracies)/tf.reduce_sum(mask)\n","# def accuracy_function(real, pred):\n","#   candidate = tf.argmax(pred, axis=2)\n","#   # print(real.)\n","#   print(real.numpy()[0][:-1])\n","#   print(tokenizer_vn.decode(real.numpy()[0][:-1]))\n","#   print(candidate.numpy()[0][:-1])\n","#   print(tokenizer_vn.decode(candidate.numpy()[0][:-1]))\n","#   # print(candidate)\n","#   # score = bleu_score(real, candidate)\n","#   score = 12\n","#   print(score)\n","#   return tf.constant(score)\n","# # bleu_function('real', 'pred')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sPfZsplvJ0sG"},"outputs":[],"source":["# dir(tokenizer_vn)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ggV3cc5-LyNX"},"outputs":[],"source":["# for i in content_vn[:12]:\n","#   if 'mãnh_' in i:\n","#     print(i)  "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DIFfKbIEJ8P4"},"outputs":[],"source":["# for i in range(100000):\n","#   print(tokenizer_vn._id_to_subword(i).encode('utf-8').decode('utf-8'))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uOSeW1vcfTWa"},"outputs":[],"source":["from collections import Counter\n","import math\n","def n_gram_generator(sentence,n= 2,n_gram= False):\n","    '''\n","    N-Gram generator with parameters sentence\n","    n is for number of n_grams\n","    The n_gram parameter removes repeating n_grams \n","    '''\n","    sentence = sentence.lower() # converting to lower case\n","    sent_arr = np.array(sentence.split()) # split to string arrays\n","    length = len(sent_arr)\n","\n","    word_list = []\n","    for i in range(length+1):\n","        if i < n:\n","            continue\n","        word_range = list(range(i-n,i))\n","        s_list = sent_arr[word_range]\n","        string = ' '.join(s_list) # converting list to strings\n","        word_list.append(string) # append to word_list\n","        if n_gram:\n","            word_list = list(set(word_list))\n","    return word_list\n","def bleu_score(original,machine_translated):\n","    '''\n","    Bleu score function given a orginal and a machine translated sentences\n","    '''\n","    mt_length = len(machine_translated.split())\n","    o_length = len(original.split())\n","\n","    # Brevity Penalty \n","    if mt_length>o_length:\n","        BP=1\n","    else:\n","        penality=1-(mt_length/o_length)\n","        BP=np.exp(penality)\n","\n","    # Clipped precision\n","    clipped_precision_score = []\n","    for i in range(1, 5):\n","        original_n_gram = Counter(n_gram_generator(original,i))\n","        machine_n_gram = Counter(n_gram_generator(machine_translated,i))\n","\n","        c = sum(machine_n_gram.values())\n","        for j in machine_n_gram:\n","            if j in original_n_gram:\n","                if machine_n_gram[j] > original_n_gram[j]:\n","                    machine_n_gram[j] = original_n_gram[j]\n","            else:\n","                machine_n_gram[j] = 0\n","\n","        #print (sum(machine_n_gram.values()), c)\n","        clipped_precision_score.append(sum(machine_n_gram.values())/c)\n","\n","    #print (clipped_precision_score)\n","\n","    weights =[0.25]*4\n","\n","    s = (w_i * math.log(p_i) for w_i, p_i in zip(weights, clipped_precision_score))\n","    s = BP * math.exp(math.fsum(s))\n","    return s\n","\n","original = \"It is a guide to action which ensures that the military alwasy obeys the command of the party\"\n","machine_translated = \"It is the guiding principle which guarantees the military forces alwasy being under the command of the party\"\n","\n","# print (bleu_score(original, machine_translated))\n","# print (sentence_bleu([original.split()], machine_translated.split()))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"phlyxMnm-Tpx"},"outputs":[],"source":["loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n","    from_logits=True, reduction='none')\n","train_loss = tf.keras.metrics.Mean(name='train_loss')\n","train_accuracy = tf.keras.metrics.Mean(\n","    name='train_accuracy')"]},{"cell_type":"markdown","metadata":{"id":"aeHumfr7zmMa"},"source":["## Training and checkpointing"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UiysUa--4tOU"},"outputs":[],"source":["transformer = Transformer(num_layers, d_model, num_heads, dff,\n","                          input_vocab_size, target_vocab_size, \n","                          pe_input=input_vocab_size, \n","                          pe_target=target_vocab_size,\n","                          rate=dropout_rate)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZOJUSB1T8GjM"},"outputs":[],"source":["def create_masks(inp, tar):\n","  # Encoder padding mask\n","  enc_padding_mask = create_padding_mask(inp)\n","  \n","  # Used in the 2nd attention block in the decoder.\n","  # This padding mask is used to mask the encoder outputs.\n","  dec_padding_mask = create_padding_mask(inp)\n","  \n","  # Used in the 1st attention block in the decoder.\n","  # It is used to pad and mask future tokens in the input received by \n","  # the decoder.\n","  look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1])\n","  dec_target_padding_mask = create_padding_mask(tar)\n","  combined_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n","  \n","  return enc_padding_mask, combined_mask, dec_padding_mask"]},{"cell_type":"markdown","metadata":{"id":"Fzuf06YZp66w"},"source":["Create the checkpoint path and the checkpoint manager. This will be used to save checkpoints every `n` epochs."]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1652851659787,"user":{"displayName":"Tiến Lê Văn","userId":"05205815886898954704"},"user_tz":-420},"id":"hNhuYfllndLZ","colab":{"base_uri":"https://localhost:8080/"},"outputId":"f0221914-c043-4e34-f396-d78b5cd9c23a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Latest checkpoint restored!!\n"]}],"source":["checkpoint_path = \"/content/drive/MyDrive/Colab Notebooks/train1\"\n","\n","ckpt = tf.train.Checkpoint(transformer=transformer,\n","                           optimizer=optimizer)\n","\n","ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n","\n","# if a checkpoint exists, restore the latest checkpoint.\n","if ckpt_manager.latest_checkpoint:\n","  ckpt.restore(ckpt_manager.latest_checkpoint)\n","  print ('Latest checkpoint restored!!')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xPy8qKkiLDwM"},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow import keras"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UWZIMEVZ8eTl"},"outputs":[],"source":["# The @tf.function trace-compiles train_step into a TF graph for faster\n","# execution. The function specializes to the precise shape of the argument\n","# tensors. To avoid re-tracing due to the variable sequence lengths o4/1AY0e-g5NwERYfvXHd5gYJ0PO1FU94gGYrmyMq14BU0Dlvo5oiSqu1suLElor variable\n","# batch sizes (the last batch is smaller), use input_signature to specify\n","# more generic shapes.\n","\n","train_step_signature = [\n","    tf.TensorSpec(shape=(None, None), dtype=tf.int64),\n","    tf.TensorSpec(shape=(None, None), dtype=tf.int64),\n","]\n","\n","@tf.function(input_signature=train_step_signature)\n","def train_step(inp, tar):\n","  # print('inner train')\n","  tar_inp = tar[:, :-1]\n","  tar_real = tar[:, 1:]\n","  \n","  enc_padding_mask, combined_mask, dec_padding_mask = create_masks(inp, tar_inp)\n","  \n","  with tf.GradientTape() as tape:\n","    # print('---------------------------------')\n","    predictions, _ = transformer(inp, tar_inp, \n","                                 True, \n","                                 enc_padding_mask, \n","                                 combined_mask, \n","                                 dec_padding_mask)\n","    loss = loss_function(tar_real, predictions)\n","  gradients = tape.gradient(loss, transformer.trainable_variables)    \n","  optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n","  \n","  train_loss(loss)\n","  # print('--------------------')\n","  # print(accuracy_function(tar_real, predictions))\n","  # print('--------------------')\n","  train_accuracy(accuracy_function(tar_real, predictions))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"H315b1hp8e9D","colab":{"base_uri":"https://localhost:8080/","height":394},"executionInfo":{"status":"error","timestamp":1652851788114,"user_tz":-420,"elapsed":2060,"user":{"displayName":"Tiến Lê Văn","userId":"05205815886898954704"}},"outputId":"66bcfe45-464c-4075-aa83-a3869884f034"},"outputs":[{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-147-768c7eaae59f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0;31m# inp -> en, tar -> vn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m50\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not callable"]}],"source":["EPOCHS = 10\n","for epoch in range(EPOCHS):\n","  start = time.time()\n","  \n","  train_loss.reset_states()\n","  train_accuracy.reset_states()\n","  \n","  # inp -> en, tar -> vn\n","  for (batch, (inp, tar)) in enumerate(train_dataset):\n","    train_step(inp, tar)\n","    \n","    if batch % 50 == 0:\n","      print ('Epoch {} Batch {} Loss {:.4f} Accuracy {:.4f}'.format(\n","          epoch + 1, batch, train_loss.result(), train_accuracy.result()))\n","      \n","  if (epoch + 1) % 50 == 0:\n","    ckpt_save_path = ckpt_manager.save()\n","    print ('Saving checkpoint for epoch {} at {}'.format(epoch+1,\n","                                                         ckpt_save_path))\n","    \n","  print ('Epoch {} Loss {:.4f} Accuracy {:.4f}'.format(epoch + 1, \n","                                                train_loss.result(), \n","                                                train_accuracy.result()))\n","\n","  print ('Time taken for 1 epoch: {} secs\\n'.format(time.time() - start))"]},{"cell_type":"code","source":["transformer.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":298},"id":"pDoGJfunkmKM","executionInfo":{"status":"error","timestamp":1652851189296,"user_tz":-420,"elapsed":292,"user":{"displayName":"Tiến Lê Văn","userId":"05205815886898954704"}},"outputId":"afb262cb-251f-482c-9133-b61e794a99c6"},"execution_count":null,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-95-b0463e4f27a6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36msummary\u001b[0;34m(self, line_length, positions, print_fn, expand_nested, show_trainable)\u001b[0m\n\u001b[1;32m   2774\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2775\u001b[0m       raise ValueError(\n\u001b[0;32m-> 2776\u001b[0;31m           \u001b[0;34m'This model has not yet been built. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2777\u001b[0m           \u001b[0;34m'Build the model first by calling `build()` or by calling '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2778\u001b[0m           'the model on a batch of data.')\n","\u001b[0;31mValueError\u001b[0m: This model has not yet been built. Build the model first by calling `build()` or by calling the model on a batch of data."]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QPtAZFLpkw8z"},"outputs":[],"source":["ckpt_save_path = ckpt_manager.save()"]},{"cell_type":"markdown","metadata":{"id":"QfcsSWswSdGV"},"source":["## Evaluate"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5buvMlnvyrFm"},"outputs":[],"source":["def evaluate(inp_sentence):\n","    start_token = [tokenizer_cn.vocab_size]\n","    end_token = [tokenizer_cn.vocab_size + 1]\n","\n","    # inp sentence is eng, hence adding the start and end token\n","    inp_sentence = start_token + tokenizer_cn.encode(inp_sentence) + end_token\n","    encoder_input = tf.expand_dims(inp_sentence, 0)\n","\n","    # as the target is vn, the first word to the transformer should be the\n","    # english start token.\n","    decoder_input = [tokenizer_vn.vocab_size]\n","    output = tf.expand_dims(decoder_input, 0)\n","\n","\n","    enc_padding_mask, combined_mask, dec_padding_mask = create_masks(\n","        encoder_input, output)\n","    enc_output = transformer.encoder(encoder_input, False, enc_padding_mask)\n","    \n","    for i in range(MAX_LENGTH):\n","        enc_padding_mask, combined_mask, dec_padding_mask = create_masks(\n","            encoder_input, output)\n","        dec_output, attention_weights = transformer.decoder(\n","            output, enc_output, False, combined_mask, dec_padding_mask)\n","        predictions = transformer.final_layer(dec_output)\n","        predictions = predictions[: ,-1:, :]  # (batch_size, 1, vocab_size)\n","        predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n","        if predicted_id == tokenizer_vn.vocab_size+1:\n","            return tf.squeeze(output, axis=0), attention_weights\n","        output = tf.concat([output, predicted_id], axis=-1)\n","    return tf.squeeze(output, axis=0), attention_weights"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lU2_yG_vBGza"},"outputs":[],"source":["def translate(sentence, plot=''):\n","  sentence = preproces_cn(sentence)\n","  result, attention_weights = evaluate(sentence)\n","  predicted_sentence = tokenizer_vn.decode([i for i in result \n","                                            if i < tokenizer_vn.vocab_size])  \n","\n","  print('Input: {}'.format(sentence))\n","  print('Predicted translation: {}'.format(predicted_sentence))\n","  return predicted_sentence"]},{"cell_type":"code","source":["data_test = train_pairs[:7000] + test_pairs[:3000] \n","from nltk.translate.bleu_score import sentence_bleu\n","\n","scores_bleu = 0\n","count_bleu = 0\n","\n","for i in data_test[:100]:\n","      predict = translate(i[0])\n","      score = sentence_bleu(i[1], predict)\n","      scores_bleu += score\n","      count_bleu += 1\n","      print('Trung: ', i[0])\n","      print('actual: ', i[1])\n","      print('predicted: ', predict)\n","      print(score)\n","      print(count_bleu, end='-')\n","\n","print('\\n\\nCount_bleu: ', count_bleu)\n","print('AVERAGE BLEU SCORE: ', scores_bleu/count_bleu)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kM7BQnChhl7d","executionInfo":{"status":"ok","timestamp":1652787606026,"user_tz":-420,"elapsed":118339,"user":{"displayName":"Tiến Lê Văn","userId":"05205815886898954704"}},"outputId":"dcb116aa-e57d-41fc-f7d1-314c42e66f28"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Input: 下 滑\n","Predicted translation: từ chối\n","kr:  下 滑\n","actual:  từ chối\n","predicted:  từ chối\n","1.0\n","1-"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n","Corpus/Sentence contains 0 counts of 2-gram overlaps.\n","BLEU scores might be undesirable; use SmoothingFunction().\n","  warnings.warn(_msg)\n"]},{"output_type":"stream","name":"stdout","text":["Input: 主 导\n","Predicted translation: dẫn đầu\n","kr:  主 导\n","actual:  dẫn đầu\n","predicted:  dẫn đầu\n","1.0\n","2-Input: 團 結\n","Predicted translation: thống nhất\n","kr:  團 結\n","actual:  thống nhất\n","predicted:  thống nhất\n","0.9146912192286945\n","3-Input: 苏 木 无 语 ， 这 还 真 是 自 己 的 师 兄 呢 。\n","Predicted translation: tô mộc im lặng, người này đúng là sư huynh của hắn.\n","kr:  苏 木 无 语 ， 这 还 真 是 自 己 的 师 兄 呢 。\n","actual:  tô mộc im lặng, người này đúng là sư huynh của hắn.\n","predicted:  tô mộc im lặng, người này đúng là sư huynh của hắn.\n","0.8367437134595066\n","4-Input: 新 羅\n","Predicted translation: silla\n","kr:  新 羅\n","actual:  silla\n","predicted:  silla\n","0.9457416090031758\n","5-Input: 监 视\n","Predicted translation: giám sát\n","kr:  监 视\n","actual:  giám sát\n","predicted:  giám sát\n","0.9671682101338347\n","6-Input: 屹\n","Predicted translation: yi\n","kr:  屹\n","actual:  yi\n","predicted:  yi\n","1.0\n","7-Input: 这 个 节 目 她 演 得 好 不 好 ？\n","Predicted translation: bạn biểu mục này diễn văn cô ta thế nào?\n","kr:  这 个 节 目 她 演 得 好 不 好 ？\n","actual:  tiết mục này cô ta diễn có tốt không?\n","predicted:  bạn biểu mục này diễn văn cô ta thế nào?\n","0.7952707287670506\n","8-Input: 蘭\n","Predicted translation: màu xanh da trời\n","kr:  蘭\n","actual:  màu xanh da trời\n","predicted:  màu xanh da trời\n","0.9494144610579709\n","9-Input: 片 刻 后 ， 一 道 魁 梧 的 身 影 闪 身 而 进 ， 正 是 犀 雷 ， 一 脸 尴 尬 地 道 ： “ 大 人 你 怎 么 来 了 ？ ” 不 小 心 被 杨 开 看 到 了 本 体 ， 确 实 有 够 尴 尬 的 ， 他 虽 然 出 身 妖 族 ， 但 自 化 形 以 来 便 很 少 露 出 真 身 了 ， 除 非 与 敌 人 大 战 僵 持 不 下 要 拼 命 时 。\n","Predicted translation:  dương khai gật đầu, mỉm cười nhìn về phía trước, phòng kia.\n","kr:  片 刻 后 ， 一 道 魁 梧 的 身 影 闪 身 而 进 ， 正 是 犀 雷 ， 一 脸 尴 尬 地 道 ： “ 大 人 你 怎 么 来 了 ？ ” 不 小 心 被 杨 开 看 到 了 本 体 ， 确 实 有 够 尴 尬 的 ， 他 虽 然 出 身 妖 族 ， 但 自 化 形 以 来 便 很 少 露 出 真 身 了 ， 除 非 与 敌 人 大 战 僵 持 不 下 要 拼 命 时 。\n","actual:   bốn mắt nhìn nhau, dương khai nhẹ nhàng gật đầu, chợt lách người tiến vào bên trong một cái hố.\n","predicted:   dương khai gật đầu, mỉm cười nhìn về phía trước, phòng kia.\n","0.7868539809690807\n","10-Input: 教 仁\n","Predicted translation: dạy lòng nhân từ\n","kr:  教 仁\n","actual:  dạy lòng nhân từ\n","predicted:  dạy lòng nhân từ\n","0.9306048591020996\n","11-Input: 墳 場\n","Predicted translation: phần bay\n","kr:  墳 場\n","actual:  nghĩa trang\n","predicted:  phần bay\n","0.8408964152537145\n","12-Input: 同 类\n","Predicted translation: giống\n","kr:  同 类\n","actual:  giống\n","predicted:  giống\n","0.9457416090031758\n","13-Input: 潛 在\n","Predicted translation: tiềm năng\n","kr:  潛 在\n","actual:  tiềm năng\n","predicted:  tiềm năng\n","0.9709835434146469\n","14-Input: 总 是\n","Predicted translation: luôn luôn\n","kr:  总 是\n","actual:  luôn luôn\n","predicted:  luôn luôn\n","0.8633400213704505\n","15-Input: 原 有\n","Predicted translation: nguyên\n","kr:  原 有\n","actual:  nguyên\n","predicted:  nguyên\n","0.9554427922043668\n","16-Input: 發 掘\n","Predicted translation: khai quật\n","kr:  發 掘\n","actual:  khai quật\n","predicted:  khai quật\n","1.0\n","17-Input: 侦 察\n","Predicted translation: do thám\n","kr:  侦 察\n","actual:  do thám\n","predicted:  do thám\n","1.0\n","18-Input: 勢\n","Predicted translation: tiềm năng\n","kr:  勢\n","actual:  tiềm năng\n","predicted:  tiềm năng\n","0.9709835434146469\n","19-Input: 我 买 了 一 件 毛 衣 。\n","Predicted translation: tôi mua một chiếc áo len.\n","kr:  我 买 了 一 件 毛 衣 。\n","actual:  tôi đã mua một chiếc áo len.\n","predicted:  tôi mua một chiếc áo len.\n","0.9080865185231703\n","20-Input: 專 注 於\n","Predicted translation: tập trung vào\n","kr:  專 注 於\n","actual:  tập trung vào\n","predicted:  tập trung vào\n","0.9590965597935381\n","21-Input: 水 月 星 ， 恒 罗 商 会 的 主 星 。\n","Predicted translation:   thủy nguyệt tinh, hằng la thương hội chủ tinh. \n","kr:  水 月 星 ， 恒 罗 商 会 的 主 星 。\n","actual:    thủy nguyệt tinh, hằng la thương hội chủ tinh. \n","predicted:    thủy nguyệt tinh, hằng la thương hội chủ tinh. \n","0.7891133309463471\n","22-Input: 你 们 别 客 气 ， 就 像 在 家 一 样 吧 。\n","Predicted translation: các bạn đừng khách sáo, cứ coi như ở nhà nhé.\n","kr:  你 们 别 客 气 ， 就 像 在 家 一 样 吧 。\n","actual:  các bạn đừng khách sáo, cứ coi như ở nhà nhé.\n","predicted:  các bạn đừng khách sáo, cứ coi như ở nhà nhé.\n","0.8265168183793802\n","23-Input: 被 控\n","Predicted translation: bị tô cáo\n","kr:  被 控\n","actual:  bị tô cáo\n","predicted:  bị tô cáo\n","0.9709835434146469\n","24-Input: 碰\n","Predicted translation: trước mặt\n","kr:  碰\n","actual:  băng\n","predicted:  trước mặt\n","0\n","25-Input: 自 动 调 节 器\n","Predicted translation: máy điều chỉnh tuyệt chỉnh tự động\n","kr:  自 动 调 节 器\n","actual:  thiết bị điều chỉnh tự động\n","predicted:  máy điều chỉnh tuyệt chỉnh tự động\n","0.7863503941633413\n","26-Input: 生 病\n","Predicted translation: đau ốm\n","kr:  生 病\n","actual:  đau ốm\n","predicted:  đau ốm\n","1.0\n","27-Input: 相 位\n","Predicted translation: giai đoạn\n","kr:  相 位\n","actual:  giai đoạn\n","predicted:  giai đoạn\n","0.9709835434146469\n","28-Input: 立 宪\n","Predicted translation: tổ chức\n","kr:  立 宪\n","actual:  tổ chức\n","predicted:  tổ chức\n","0.9621954581957615\n","29-Input: 而 且 自 己 刚 才 既 然 感 知 到 了 她 的 存 在 ， 她 会 不 会 已 经 发 现 了 自 己 ？\n","Predicted translation:  mà mình vừa rồi nếu cảm giác được nàng tồn tại, nàng có thể phát hiện mình hay không?\n","kr:  而 且 自 己 刚 才 既 然 感 知 到 了 她 的 存 在 ， 她 会 不 会 已 经 发 现 了 自 己 ？\n","actual:   mà mình vừa rồi nếu cảm giác được nàng tồn tại, nàng có thể đã phát hiện mình hay không?\n","predicted:   mà mình vừa rồi nếu cảm giác được nàng tồn tại, nàng có thể phát hiện mình hay không?\n","0.7810213065790322\n","30-Input: 电 子\n","Predicted translation: điện tử\n","kr:  电 子\n","actual:  điện tử\n","predicted:  điện tử\n","1.0\n","31-Input: 民 主\n","Predicted translation: dân chủ\n","kr:  民 主\n","actual:  dân chủ\n","predicted:  dân chủ\n","1.0\n","32-Input: 问 我 想 不 想 跟 她 一 起 去 。\n","Predicted translation: hỏi tôi có muốn đi không.\n","kr:  问 我 想 不 想 跟 她 一 起 去 。\n","actual:  hỏi tôi có muốn đi cùng cô ta không.\n","predicted:  hỏi tôi có muốn đi không.\n","0.8944271909999159\n","33-Input: 万 维 网\n","Predicted translation: www\n","kr:  万 维 网\n","actual:  world wide web\n","predicted:  www\n","0.7598356856515925\n","34-Input: 糯\n","Predicted translation: sáp\n","kr:  糯\n","actual:  sáp\n","predicted:  sáp\n","1.0\n","35-Input: 祝 晴 脸 色 苍 白 。\n","Predicted translation:   chúc liệt một mặt kinh ngạc. \n","kr:  祝 晴 脸 色 苍 白 。\n","actual:    chúc tình sắc mặt tái nhợt. \n","predicted:    chúc liệt một mặt kinh ngạc. \n","0.7536324264832723\n","36-Input: 計 約\n","Predicted translation: lên lịch\n","kr:  計 約\n","actual:  lên lịch\n","predicted:  lên lịch\n","0.9671682101338347\n","37-Input: 文 集\n","Predicted translation: tác phẩm được sưu tầm\n","kr:  文 集\n","actual:  tác phẩm được sưu tầm\n","predicted:  tác phẩm được sưu tầm\n","0.9036020036098448\n","38-Input: 币\n","Predicted translation: tiền tệ\n","kr:  币\n","actual:  tiền tệ\n","predicted:  tiền tệ\n","0.9621954581957615\n","39-Input: 伯 母\n","Predicted translation: bác gái\n","kr:  伯 母\n","actual:  bác gái\n","predicted:  bác gái\n","0.9621954581957615\n","40-Input: 省 長\n","Predicted translation: thống đốc\n","kr:  省 長\n","actual:  thống đốc\n","predicted:  thống đốc\n","0.9709835434146469\n","41-Input: 我 就 在 越 南 。\n","Predicted translation: em ở việt nam.\n","kr:  我 就 在 越 南 。\n","actual:  em ở việt nam.\n","predicted:  em ở việt nam.\n","0.94149097734812\n","42-Input: 對 黨\n","Predicted translation: đối lập\n","kr:  對 黨\n","actual:  đối lập\n","predicted:  đối lập\n","1.0\n","43-Input: 做 出\n","Predicted translation: làm\n","kr:  做 出\n","actual:  làm\n","predicted:  làm\n","1.0\n","44-Input: 她 有 点 儿 不 舒 服 ， 发 烧 、 头 疼 ， 可 能 感 冒 了 。\n","Predicted translation: cô ta hơi khó chịu chút xíu\n","kr:  她 有 点 儿 不 舒 服 ， 发 烧 、 头 疼 ， 可 能 感 冒 了 。\n","actual:  cô ta hơi khó chịu chút xíu, bị sốt, đau đầu, có thể là bị cảm rồi.\n","predicted:  cô ta hơi khó chịu chút xíu\n","0.8633400213704505\n","45-Input: 磊\n","Predicted translation: tấn\n","kr:  磊\n","actual:  lei\n","predicted:  tấn\n","0\n","46-Input: 伉\n","Predicted translation: tong\n","kr:  伉\n","actual:  tong\n","predicted:  tong\n","1.0\n","47-Input: 时 刻\n","Predicted translation: thời gian sau\n","kr:  时 刻\n","actual:  thời gian\n","predicted:  thời gian sau\n","0.8857000285382948\n","48-Input: 本 年\n","Predicted translation: năm nay\n","kr:  本 年\n","actual:  năm nay\n","predicted:  năm nay\n","0.9621954581957615\n","49-Input: “ 搞 什 么 ！ ” 苍 老 声 音 的 主 人 一 头 雾 水 。\n","Predicted translation:  \"còn có người khác một người điều gì?\" hạ ngưng thường lạnh rên hỏi.\n","kr:  “ 搞 什 么 ！ ” 苍 老 声 音 的 主 人 一 头 雾 水 。\n","actual:    “làm cái gì!” thanh âm già nua chủ nhân không hiểu ra sao. \n","predicted:   \"còn có người khác một người điều gì?\" hạ ngưng thường lạnh rên hỏi.\n","0.6828267746069693\n","50-Input: 地 下 室\n","Predicted translation: tầng hầm\n","kr:  地 下 室\n","actual:  tầng hầm\n","predicted:  tầng hầm\n","0.9671682101338347\n","51-Input: 投 擲\n","Predicted translation: phi\n","kr:  投 擲\n","actual:  phi\n","predicted:  phi\n","1.0\n","52-Input: 船\n","Predicted translation: chiếc phà\n","kr:  船\n","actual:  chiếc phà\n","predicted:  chiếc phà\n","0.9391044157537525\n","53-Input: 刲\n","Predicted translation: mở và làm sạch\n","kr:  刲\n","actual:  mở và làm sạch\n","predicted:  mở và làm sạch\n","0.9193227152249185\n","54-Input: 祝 炎 道 ： “ 不 必 找 ， 你 自 有 这 个 能 力 。 ”\n","Predicted translation:  chúc viêm nói: \"không cần tìm, ngươi tự có năng lực này.\"\n","kr:  祝 炎 道 ： “ 不 必 找 ， 你 自 有 这 个 能 力 。 ”\n","actual:   chúc viêm nói: \"không cần tìm, ngươi tự có năng lực này.\"\n","predicted:   chúc viêm nói: \"không cần tìm, ngươi tự có năng lực này.\"\n","0.8260074086962012\n","55-Input: 你 哥 哥 在 哪 儿 买 这 个 手 机 号 ？\n","Predicted translation: anh trai bạn để bạn mua số di động này ở đâu?\n","kr:  你 哥 哥 在 哪 儿 买 这 个 手 机 号 ？\n","actual:  anh trai bạn mua số di động này ở đâu?\n","predicted:  anh trai bạn để bạn mua số di động này ở đâu?\n","0.8361853256187297\n","56-Input: 捕 獵\n","Predicted translation: thâm liệu các người\n","kr:  捕 獵\n","actual:  săn bắn\n","predicted:  thâm liệu các người\n","0.5695988432761473\n","57-Input: 樣 貌\n","Predicted translation: đồng ý\n","kr:  樣 貌\n","actual:  xuất hiện\n","predicted:  đồng ý\n","0.7598356856515925\n","58-Input: 开 学\n","Predicted translation: khai giảng\n","kr:  开 学\n","actual:  khai giảng\n","predicted:  khai giảng\n","0.9457416090031758\n","59-Input: 溶 剂\n","Predicted translation: dung môi\n","kr:  溶 剂\n","actual:  dung môi\n","predicted:  dung môi\n","1.0\n","60-Input: 辥\n","Predicted translation: kéo dài\n","kr:  辥\n","actual:  kéo dài\n","predicted:  kéo dài\n","1.0\n","61-Input: 真 是 见 鬼 了 ！\n","Predicted translation:   thật là gặp quỷ! \n","kr:  真 是 见 鬼 了 ！\n","actual:    thật sự là gặp quỷ! \n","predicted:    thật là gặp quỷ! \n","0.9094889729229877\n","62-Input: “ 你 喊 我 ？ ” 碧 落 扭 头 望 她 。\n","Predicted translation:   “ngươi gọi ta?” bích lạc quay đầu nhìn nàng. \n","kr:  “ 你 喊 我 ？ ” 碧 落 扭 头 望 她 。\n","actual:    “ngươi gọi ta?” bích lạc quay đầu nhìn nàng. \n","predicted:    “ngươi gọi ta?” bích lạc quay đầu nhìn nàng. \n","0.8624201052838518\n","63-Input: 銷 售\n","Predicted translation: bán hàng\n","kr:  銷 售\n","actual:  bán hàng\n","predicted:  bán hàng\n","0.9671682101338347\n","64-Input: 也 帮 我 挡 住 狂 风 暴 雨\n","Predicted translation: cũng để anh che chở cho em khỏi bão táp phong ba\n","kr:  也 帮 我 挡 住 狂 风 暴 雨\n","actual:  cũng để anh che chở cho em khỏi bão táp phong ba\n","predicted:  cũng để anh che chở cho em khỏi bão táp phong ba\n","0.8132882808488929\n","65-Input: 絎\n","Predicted translation: may chăn\n","kr:  絎\n","actual:  may chăn\n","predicted:  may chăn\n","1.0\n","66-Input: 店 舖\n","Predicted translation: cửa tiệm\n","kr:  店 舖\n","actual:  cửa tiệm\n","predicted:  cửa tiệm\n","1.0\n","67-Input: 咙\n","Predicted translation: họng\n","kr:  咙\n","actual:  họng\n","predicted:  họng\n","1.0\n","68-Input: 怎 么 拼 命 忘 却 还 是 忘 不 掉\n","Predicted translation: liều mạng quên thế nào đi nữa cũng không quên được\n","kr:  怎 么 拼 命 忘 却 还 是 忘 不 掉\n","actual:  liều mạng quên thế nào đi nữa cũng không quên được\n","predicted:  liều mạng quên thế nào đi nữa cũng không quên được\n","0.8408964152537145\n","69-Input: 你 快 把 作 业 做 了 吧 。\n","Predicted translation: bạn làm bài tập nhanh lên đi.\n","kr:  你 快 把 作 业 做 了 吧 。\n","actual:  bạn làm bài tập nhanh lên đi.\n","predicted:  bạn làm bài tập nhanh lên đi.\n","0.8618476389178121\n","70-Input: 樂 曲\n","Predicted translation: âm nhạc\n","kr:  樂 曲\n","actual:  âm nhạc\n","predicted:  âm nhạc\n","1.0\n","71-Input: 许 久 之 后 ， 他 才 开 口 问 道 ： “ 家 主 ， 这 灵 丹 果 真 有 那 等 神 效 ？ ”\n","Predicted translation: sức khỏe\n","kr:  许 久 之 后 ， 他 才 开 口 问 道 ： “ 家 主 ， 这 灵 丹 果 真 有 那 等 神 效 ？ ”\n","actual:    hồi lâu sau, hắn mới mở miệng hỏi: “gia chủ, linh đan này quả thực có cấp độ kia thần hiệu?” \n","predicted:  sức khỏe\n","0.9306048591020996\n","72-Input: 蚺\n","Predicted translation: con trăn\n","kr:  蚺\n","actual:  anaconda\n","predicted:  con trăn\n","0.7825422900366437\n","73-Input: 打 死\n","Predicted translation: giết chết\n","kr:  打 死\n","actual:  giết chết\n","predicted:  giết chết\n","0.9391044157537525\n","74-Input: 繁 忙 時 間\n","Predicted translation: thời gian bận rộn\n","kr:  繁 忙 時 間\n","actual:  thời gian bận rộn\n","predicted:  thời gian bận rộn\n","0.9166068134248218\n","75-Input: 上 半 年\n","Predicted translation: nửa đầu\n","kr:  上 半 年\n","actual:  nửa đầu\n","predicted:  nửa đầu\n","1.0\n","76-Input: 好 吗 ？\n","Predicted translation: được không?\n","kr:  好 吗 ？\n","actual:  được không?\n","predicted:  được không?\n","1.0\n","77-Input: 滴\n","Predicted translation: rơi vãi\n","kr:  滴\n","actual:  rơi vãi\n","predicted:  rơi vãi\n","0.9621954581957615\n","78-Input: 对 外 贸 易\n","Predicted translation: ngoại thương\n","kr:  对 外 贸 易\n","actual:  ngoại thương\n","predicted:  ngoại thương\n","0.9554427922043668\n","79-Input: 他 本 是 想 在 西 域 这 边 找 一 个 隐 蔽 的 位 置 布 置 ， 如 此 一 来 日 后 也 方 便 他 来 往 ， 再 想 来 西 域 的 话 直 接 通 过 空 间 法 阵 就 心 了 ， 但 西 域 这 边 他 人 生 地 不 熟 的 ， 想 找 一 个 这 样 的 地 方 不 太 容 易 ， 可 能 要 花 费 一 两 个 月 甚 至 更 多 的 时 间 。\n","Predicted translation:   vì lẽ đó cẩn thận để để để để để để để để hắn để hắn để tô nhan giải thích được gặp phải suy nghĩ một vấn đề cùng nàng nói một chút. \n","kr:  他 本 是 想 在 西 域 这 边 找 一 个 隐 蔽 的 位 置 布 置 ， 如 此 一 来 日 后 也 方 便 他 来 往 ， 再 想 来 西 域 的 话 直 接 通 过 空 间 法 阵 就 心 了 ， 但 西 域 这 边 他 人 生 地 不 熟 的 ， 想 找 一 个 这 样 的 地 方 不 太 容 易 ， 可 能 要 花 费 一 两 个 月 甚 至 更 多 的 时 间 。\n","actual:    vì lẽ đó cẩn thận suy nghĩ một chút liền buông tha vốn có ý định. \n","predicted:    vì lẽ đó cẩn thận để để để để để để để để hắn để hắn để tô nhan giải thích được gặp phải suy nghĩ một vấn đề cùng nàng nói một chút. \n","0.6624603578601934\n","80-Input: 盏\n","Predicted translation: cốc\n","kr:  盏\n","actual:  cốc\n","predicted:  cốc\n","0.9036020036098448\n","81-Input: 铜\n","Predicted translation: đồng\n","kr:  铜\n","actual:  đồng\n","predicted:  đồng\n","1.0\n","82-Input: 红 楼\n","Predicted translation: tháp chuông\n","kr:  红 楼\n","actual:  ngôi nhà màu đỏ\n","predicted:  tháp chuông\n","0.8593887047640296\n","83-Input: 体 校\n","Predicted translation: trường thể thao\n","kr:  体 校\n","actual:  trường thể thao\n","predicted:  trường thể thao\n","0.9253911813809743\n","84-Input: 黾\n","Predicted translation: con cóc\n","kr:  黾\n","actual:  con cóc\n","predicted:  con cóc\n","0.9193227152249185\n","85-Input: 江 苏\n","Predicted translation: giang tô\n","kr:  江 苏\n","actual:  giang tô\n","predicted:  giang tô\n","0.9671682101338347\n","86-Input: 怪 不 得\n","Predicted translation: chẳng trách\n","kr:  怪 不 得\n","actual:  chẳng trách\n","predicted:  chẳng trách\n","0.9510699415570292\n","87-Input: 榮 譽\n","Predicted translation: tôn kính\n","kr:  榮 譽\n","actual:  tôn kính\n","predicted:  tôn kính\n","0.9671682101338347\n","88-Input: 焄\n","Predicted translation: yan\n","kr:  焄\n","actual:  khói từ sự hy sinh\n","predicted:  yan\n","0.9036020036098448\n","89-Input: 整 頓\n","Predicted translation: chỉnh sửa\n","kr:  整 頓\n","actual:  chỉnh sửa\n","predicted:  chỉnh sửa\n","0.9709835434146469\n","90-Input: 投 身\n","Predicted translation: cống hiến\n","kr:  投 身\n","actual:  cống hiến\n","predicted:  cống hiến\n","0.9709835434146469\n","91-Input: 主 線\n","Predicted translation: dòng chính\n","kr:  主 線\n","actual:  dòng chính\n","predicted:  dòng chính\n","0.9457416090031758\n","92-Input: “ 这 是 … … ” 杨 开 狐 疑 地 望 着 她 。\n","Predicted translation:  \"đây là. . .\" dương khai nghi ngờ nhìn nàng.\n","kr:  “ 这 是 … … ” 杨 开 狐 疑 地 望 着 她 。\n","actual:   \"đây là. . .\" dương khai nghi ngờ nhìn nàng.\n","predicted:   \"đây là. . .\" dương khai nghi ngờ nhìn nàng.\n","0.8060932264037026\n","93-Input: 同 年\n","Predicted translation: cung nam\n","kr:  同 年\n","actual:  cung nam\n","predicted:  cung nam\n","0.9671682101338347\n","94-Input: 與 這\n","Predicted translation: với cái này\n","kr:  與 這\n","actual:  với cái này\n","predicted:  với cái này\n","0.9510699415570292\n","95-Input: 林 森\n","Predicted translation: kinsen\n","kr:  林 森\n","actual:  lin sen\n","predicted:  kinsen\n","0.9036020036098448\n","96-Input: 索 倫\n","Predicted translation: solon\n","kr:  索 倫\n","actual:  solon\n","predicted:  solon\n","0.9457416090031758\n","97-Input: 巴 尔 的 摩\n","Predicted translation: baltimore\n","kr:  巴 尔 的 摩\n","actual:  baltimore\n","predicted:  baltimore\n","1.0\n","98-Input: 慌\n","Predicted translation: đốt cháy\n","kr:  慌\n","actual:  hoảng loạn\n","predicted:  đốt cháy\n","0.7071067811865476\n","99-Input: 耱\n","Predicted translation: ôm\n","kr:  耱\n","actual:  ôm\n","predicted:  ôm\n","1.0\n","100-\n","\n","Count_bleu:  100\n","AVERAGE BLEU SCORE:  0.8987005167797452\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"q-NvetisO_zp"},"outputs":[],"source":["translate('你好！') #chào bạn"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"B6HmnIESPepY"},"outputs":[],"source":["translate('好')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RBqE3S9yPapg"},"outputs":[],"source":["print(translate('听说越南的杂技很有意思，我还没看过呢。'))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"F1JClUjSPynI"},"outputs":[],"source":["print(translate('你来过越南吗？你来越南以后去过什么地方？'))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_0mV1V2YQA1b"},"outputs":[],"source":["print(translate('我是越南人')) # tôi là người VN"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cCoNoONdQQ4L"},"outputs":[],"source":["\n","translate('越南') # VN"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"J8sDnitXQykk"},"outputs":[],"source":["translate('中国') # TQ"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cHQuNXaQRPfh"},"outputs":[],"source":["translate('明天')  # ngày mai"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vect-uIgRbQw"},"outputs":[],"source":["translate('我哥哥') # anh trai tôi"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YsxrAlvFG8SZ"},"outputs":[],"source":["print(translate('那是英文杂志。'))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4dSHKHzYRyto"},"outputs":[],"source":["translate('那是英文杂志。')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BK7g3qnxR-V2"},"outputs":[],"source":["translate('英') # tieengs Anh"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oeBxy7LySoUp"},"outputs":[],"source":["translate('今天我的工作不太忙。') #Hôm nay công việc của tôi không quá bận."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Pg9TeVwhSvPt"},"outputs":[],"source":["translate('今天') # ngày nay, hiện tại"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"J2d4rFZuS05R"},"outputs":[],"source":["translate('工作') # công việc"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9bJ2S0x4TNMV"},"outputs":[],"source":["translate('拼命在脑海中寻你') #Khao khát tìm kiếm bạn trong tâm trí của tôi"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FPux5SdZTgHe"},"outputs":[],"source":["translate('默守着那个秘密') # âm thầm giữ kín bí mật"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lfAdutaXT_Ht"},"outputs":[],"source":["translate('个秘密') # bí mật"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iPpcL8-zUJ3q"},"outputs":[],"source":["translate('请把飞机票和护照给我看一下儿。') #hãy đưa vé máy bay và hộ chiếu cho tôi xem một chút."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cS3iLb_oUbWk"},"outputs":[],"source":["translate('护照') # hộ chiếu"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"t7x7m65BOcMX"},"outputs":[],"source":["print(translate('明天下了课我就去办公室找她。')) # Tôi sẽ đến văn phòng để tìm cô ấy sau giờ học vào ngày mai."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uSlVcHVBfh-m"},"outputs":[],"source":["print(translate('真正的失败从来都不是结果的不仅如人意，而是拥有的时候随意挥霍，和未曾用心尝试前的轻言放弃。')) #Thất bại thực sự không bao giờ là kết quả của việc không chỉ đạt được yêu cầu mà còn là sự phung phí khi bạn có nó, và bỏ cuộc nhẹ nhàng trước khi cố gắng hết sức."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0JQrqaPZO40H"},"outputs":[],"source":["print(translate('真正的失败从来都不是结果的不仅如人意，而是拥有的时候随意挥霍，和未曾用心尝试前的轻言放弃。'))\n","# Thất bại thực sự không bao giờ là kết quả của việc không chỉ đạt được yêu cầu mà còn là sự phung phí khi bạn có nó, và bỏ cuộc nhẹ nhàng trước khi cố gắng hết sức."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pQ7zPBmBOQOS"},"outputs":[],"source":["print(translate('你的名字写下来不过几厘米长，却贯穿了我这么长时光。其实你不知道，你一直是我的梦想。'))\n","# Tên của bạn chỉ dài vài cm khi viết ra, nhưng nó đã xuyên suốt thời gian của tôi. Thực ra bạn không biết, bạn đã luôn là giấc mơ của tôi."]},{"cell_type":"code","source":[""],"metadata":{"id":"xKnFC1gW5xhO"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"transformer.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.3"}},"nbformat":4,"nbformat_minor":0}